name: "tpcds-1g task"

on:
  workflow_dispatch:

jobs:
  tpcds_task:
    runs-on: ubuntu-22.04
    timeout-minutes: 180
    steps:
    - run: sudo apt-get update && sudo apt-get install -y bison flex
    - name: Checkout Spark repository
      uses: actions/checkout@v4
    - name: Cache SBT and Maven
      uses: actions/cache@v4
      with:
        path: |
          build/apache-maven-*
          build/*.jar
          ~/.sbt
        key: build-${{ hashFiles('**/pom.xml', 'project/build.properties', 'build/mvn', 'build/sbt', 'build/sbt-launch-lib.bash', 'build/spark-build-info') }}
        restore-keys: |
          build-
    - name: Cache Coursier local repository
      uses: actions/cache@v4
      with:
        path: ~/.cache/coursier
        key: tpcds-coursier-${{ hashFiles('**/pom.xml', '**/plugins.sbt') }}
        restore-keys: |
          tpcds-coursier-
    - name: Install Java 17
      uses: actions/setup-java@v4
      with:
        distribution: zulu
        java-version: 17
    # - name: Cache TPC-DS generated data
    #   id: cache-tpcds-sf-1
    #   uses: actions/cache@v4
    #   with:
    #     path: ./tpcds-sf-1
    #     key: tpcds-${{ hashFiles('.github/workflows/build_and_test.yml', 'sql/core/src/test/scala/org/apache/spark/sql/TPCDSSchema.scala') }}
    # - name: Checkout tpcds-kit repository
    #   # if: steps.cache-tpcds-sf-1.outputs.cache-hit != 'true'
    #   uses: actions/checkout@v4
    #   with:
    #     repository: databricks/tpcds-kit
    #     # ref: 2a5078a782192ddb6efbcead8de9973d6ab4f069
    #     path: ./tpcds-kit
    - name: Download chukonu binary
      run: |
        wget https://github.com/fanzi2009/spark/releases/download/v3.5.1/chukonu.tgz 
        tar zxvf chukonu.tgz -C /opt
        mkdir /opt/staging
        mkdir /opt/cache        
    - name: Run Test
      run: |
        build/sbt "sql/testOnly org.apache.spark.sql.MySuite"
      env:
        LD_LIBRARY_PATH: |
          /opt/cache
          /opt/chukonu/lib

    # - name: Build tpcds-kit
    #   # if: steps.cache-tpcds-sf-1.outputs.cache-hit != 'true'
    #   run: cd tpcds-kit/tools && make OS=LINUX
    # - name: Generate TPC-DS (SF=1) table data
    #   # if: steps.cache-tpcds-sf-1.outputs.cache-hit != 'true'
    #   run: build/sbt "sql/Test/runMain org.apache.spark.sql.GenTPCDSData --dsdgenDir `pwd`/tpcds-kit/tools --location `pwd`/tpcds-sf-1 --scaleFactor 1 --numPartitions 1 --overwrite"
    # - name: Run TPC-DS queries (Sort merge join)
    #   run: |
    #     SPARK_TPCDS_DATA=`pwd`/tpcds-sf-1 build/sbt "sql/testOnly org.apache.spark.sql.TPCDSQueryTestSuite"
    #   env:
    #     SPARK_ANSI_SQL_MODE: false
    #     SPARK_TPCDS_JOIN_CONF: |
    #       spark.sql.autoBroadcastJoinThreshold=-1
    #       spark.sql.join.preferSortMergeJoin=true
    #     LD_LIBRARY_PATH: |
    #       /opt/cache
    #       /opt/chukonu/lib
